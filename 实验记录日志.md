# 实验记录 Log（Mamba2 / H100）

## 基本信息
- 记录日期：2026-02-17
- 工作目录：`/nfs/hpc/share/zhanhaoc/hpe/tempopeak`
- 计算资源：`NVIDIA H100 80GB HBM3`

## 过程记录

| 时间 | 目的 | 行为 | 原因 | 结果 |
|---|---|---|---|---|
| 2026-02-17（终端序号 973） | 激活实验环境 | `source /nfs/stak/users/zhanhaoc/hpc-share/conda/bin/activate`；`conda activate sam_3d_body` | 保证依赖与 CUDA 配置一致 | 环境激活成功，提示符为 `(sam_3d_body)` |
| 2026-02-17（终端序号 974） | 验证 mamba-ssm 安装 | `python -c "import mamba_ssm; print(mamba_ssm.__version__)"` | 确认 Mamba2 可用 | 版本 `2.2.6.post3` |
| 2026-02-17（终端序号 974） | 验证 PyTorch 与 GPU | `python -c "import torch; print(torch.__version__); print(torch.cuda.is_available()); print(torch.cuda.get_device_name(0))"` | 排除 CUDA/设备不可用问题 | `2.9.1+cu126`，`True`，`NVIDIA H100 80GB HBM3` |
| 2026-02-17（终端序号 976） | 功能冒烟测试 | 运行 `python smoke_mamba.py`（`B=2,T=64,D=128`） | 验证前向是否正确、形状是否保持 | 输入输出均为 `torch.Size([2, 64, 128])`，前向成功 |
| 2026-02-17（终端序号 977） | 前向性能基准 | 运行 50 次前向（`B=8,T=64,D=128`）并统计平均时延 | 评估时序模块是否为瓶颈 | `avg time: 0.003558688163757324`（约 `3.56 ms/forward`） |
| 2026-02-19 | 实现 BiMamba 模型 | 编写 `models/model.py` (ResNet18+BiMamba) 和 `test_model.py` | 搭建 ResNet+BiMamba 基础结构 | 代码完成，本地无 CUDA 无法冒烟，待 HPC 验证 |
| 2026-02-19 | HPC 训练冒烟测试 | 运行 `train_smoke.py` (CrossEntropy + AdamW) | 验证梯度流和 loss 收敛性 | Loss 4.15 -> 0.00，Acc -> 1.0。验证通过。 |
| 2026-02-19 | 优化模型输出 | 修改 `models/model.py` 返回 logits (移除 softmax) | 适配 PyTorch `CrossEntropyLoss` | 现在模型输出无界 logits，需在外部做 softmax |
| 2026-02-20 | 修复训练脚本 | 将 `train.py` 中的合成数据生成移出循环外 | 循环内随机数据导致无法收敛(loss停在log(64)) | 修复后期待可完美 overfit 一个 batch，验证模型拟合能力 |

## 结论
- `mamba2` 安装与 CUDA Kernel 正常。
- 当前配置下时序模块开销较小，不是主要计算瓶颈。
- 下一步：先实现 `Identity baseline`，再集成 `Bi-Mamba temporal head`。

## 实验记录 Log (SAM3(HF) / H100)

### 基本信息
- 记录日期：2026-02-20
- 工作目录：`/nfs/hpc/share/zhanhaoc/hpe/tempopeak`
- 计算资源：`NVIDIA H100 80GB HBM3`
- conda env：`sam_3d_body`
- 本地权重目录(目标)：`/nfs/hpc/share/zhanhaoc/hpe/tempopeak/models`

### 过程记录

| 阶段 / 目的 | 行为 / 指令 | 结果 / 问题 / 方案 |
| --- | --- | --- |
| 环境配置 | `conda activate sam_3d_body` | 激活成功 |
| 尝试官方 repo | `git clone facebookresearch/sam3` 并在内 `pip install -e .` | sam3==0.1.0 安装成功，但产生 Numpy 与 opencv-python 依赖冲突。导致 `smoke_sam3_video.py` 报错 `unexpected keyword argument 'device'`。决定**放弃** repo predictor，转至 HuggingFace transformers 路线。 |
| 引入 Transformers | `import Sam3VideoModel` | 报错 `cannot import name`，更新 `transformers` 至支持 sam3 层级后导入成功。 |
| 模型加载离线化 | 设置 cache_dir，尝试局域网加载 | `local_files_only=True` 依然连外网导致 `LocalEntryNotFoundError`。修复：直接将 `HF_LOCAL_MODEL` 指向内部 snapshots `<hash>` 目录，顺利在终端显示 Loading weights。 |
| 数据准备与视频 | `load_video(VIDEO_PATH)` 需要 pyav | 安装 `av` 库解决。读入 Loaded frames: 130。 |
| Tracking 接口迁移 | 梳理 `Sam3VideoProcessor` 与 `Sam3TrackerVideoModel` | 发现 Tracker 是 `post_process_masks`，PCS 是 `postprocess_outputs`。且 propagate 函数均改为 `propagate_in_video_iterator`。 |
| Tracker 初始化问题 | 尝试添加基于点的 prompt | 失败报错 `Cannot determine the starting frame index`。修复：加点后先强行执行 `_ = trk_model(..., frame_idx=fi)` 前推初始化。 |
| 精度对齐报错 | dtype 为默认 bf16 与网络内层参数碰撞 | 发生 `Input type (BFloat16) and bias type (float) should be the same`。修复方向：先强制 `dtype=torch.float32` 让整个 Pipeline 跑通。 |
| **最终目标打通** | 使用新脚本取代原架构 | **放弃 Demo 完整复现**。改为：先利用 PCS 进行 text ("tennis ball/racket") 每帧检测。当跟踪对象不在时（tracker 吐出为空），立刻把最新 centroid 送入作为新点完成 re-acquire。最终落盘为 `smoke_sam3_tracks.json` 提供每帧 2D 坐标用于后续辅助标注。 |

---

## 实验记录 Log (SAM3 Video Text Prompt Ball Tracking / H100)

### 基本信息
- 记录日期：2026-02-22
- 环境：`sam_3d_body` conda，`transformers` sam3 支持版本
- 脚本：`scripts/sam3_video_text_prompt_ball_track.py`

### 过程记录

| 阶段 / 目的 | 行为 | 结果 |
|---|---|---|
| 单帧 PCS 测试 (Text-Only) | `smoke_text_only.py` 对帧 `[0,5,10,15,20]` 仅检测 `racket`，threshold=0.5 | 效果明显改善，高置信度帧只保留真正球拍区域，输出在 `outputs/pcs_samples/` |
| 视频 Ball Tracking 冒烟 | `sam3_video_text_prompt_ball_track.py` 全程追踪，text prompt=`"ball"` | 成功处理 131 帧，输出 `outputs/sam3_video_ball_track/` ← **已验证跑通** |
| Inspect postprocess 输出结构 | HPC one-liner 打印 `processed.keys()` 与各字段 shape/device | `masks: [N,H,W] bool cuda`；`boxes: [N,4] float cuda`；`scores: [N] float cpu`；`object_ids: [N] int64 cpu`；`prompt_to_obj_ids: {'ball': [0,1,2]}` |
| Bug 修复：mask 维度假设错 | 原脚本假设 `[N,1,H,W]`，实际是 `[N,H,W]` | 已更新 `sam3_video_text_prompt_ball_track.py`，修正 mask indexing 与 `boxes.cpu()` 调用 |
| 发现：ball 自动分 3 个 instance | `prompt_to_obj_ids = {'ball': [0,1,2]}`，每帧 3 个候选 | 3 个实例中 score 最高的才是真球；后续加入 top-1 筛选逻辑 |

### 下一步
1. 在 `sam3_video_text_prompt_ball_track.py` 中加入 **只取 top-1 score 实例** 的逻辑，减少多余标注干扰。
2. 下载生成的 `outputs/sam3_video_ball_track/ball_track_vis.mp4` 到本地确认球的位置是否准确。
3. 考虑同时加入 `"racket"` prompt，生成 ball+racket 双目标追踪版本供后续辅助标注使用。
